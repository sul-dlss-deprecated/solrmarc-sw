# Properties for stanford-sw (Stanford SearchWorks) SolrMarc java code

# --- your site's basic configuration properties -------------------------------
#  for more documentation, see
#  http://code.google.com/p/solrmarc/wiki/ConfiguringSolrMarc
#   this file is read AFTER build.properties in ant build.xml

# solrmarc.solr.war.path - must point to either a war file for the version of Solr that
# you want to use, or to a directory of jar files extracted from a Solr war files.  If
# this is not provided, SolrMarc can only work by communicating with a running Solr server.
solrmarc.solr.war.path=${site.solr.war.path}

# - solrmarc.indexing.properties -indicates how to populate Solr index fields from
#   marc data.  This is the central configuration file for solrmarc.
solrmarc.indexing.properties = sw_index.properties

# - solrmarc.indexing.class - full name of java class with custom indexing functions. This
#   class must extend SolrIndexer; Defaults to SolrIndexer.
solrmarc.indexing.class = edu.stanford.StanfordIndexer

# - marc.permissive - if true, try to recover from errors, including records
#  with errors, when possible
marc.permissive = true

# - marc.verbose - when set to true, output much more information as each marc
#   record is ingested
marc.verbose = false

# - marc.combine_records - if a bib record with all of its holdings stuffed into
#  a bib field is too big to be exported from Sirsi as a single record, the
#  Sirsi system writes the record out multiple times with each subsequent record
#  containing a subset of the total holdings information.  When this property
#  is set, the "MarcCombiningReader" class is used to create a single marc
#  record with all of the occurrences of the given field.  That is, if the
#  Sirsi export created 3 bib records due to lots of items, and the item info
#  is in a 999 bib field, then setting marc.combined_records = 999 will
#  create a single marc record with ALL the 999 fields for importing into Solr.
marc.combine_records = 999

# FIXME:  this should be a straight classname, not this indirect switch
# - use org.solrmarc.marc.CombineMultBibsMhldsReader as the combining
#  reader wrapper for split marc records followed by mhld records
#  e.g. :    bib1 bib2 mhld2 mhld2 bib3 bib4 bib4 mhld4 mhld4 bib5 ...
stanford.combining.reader = true


# --- Solr instance properties -------------------------------------------------
#   this file is read AFTER build.properties in ant build.xml

# - solr.path - path to your Solr instance for embedded loading
#solr.path = ${solr.path}

# - solr.data.dir - path to data directory for your Solr instance for embedded loading
#   (note: Solr can be configured to use a different data directory)
#solr.data.dir = /home/blacklight/data/solr/dataBuild
#solr.data.dir = ${solr.path}/data

# - solr.hosturl - optional URL of running solr search engine for notifying Solr
# search engine to reload its index files.
solr.hosturl = https://sul-solr.stanford.edu/solr/searchworks-rdf-dev

# - solr.optimize_at_end - whether or not to optimize solr index after adding
#   data. Optimizing the index improves searching speed, but requires twice as
#   much disk space as index normally needs while optimization is in progress.
solr.optimize_at_end = false

# set to true to use SolrJ StreamingUpdateSolrServer for remote Solr Server
#  2012-08 streaming updates silently fail w unknown number of unindexed records
solrmarc.use_streaming_proxy = false
solrmarc.use_binary_request_handler = true

# -- MARC data properties ------------------------------------------------------

# - marc.source - marc source type - how should marc data be slurped
#   values are:  FILE or Z3950 or DIR
marc.source = FILE

# - marc.path - the path to the marc data file or directory containing marc files
#   you can set marc.path at command line
#marc.path = /data/marc/uni_1000000_1499999.marc

# - marc.default_encoding - possible values are MARC8, UTF-8, UNIMARC, BESTGUESS
marc.default_encoding = MARC8

# - marc.to_utf_8 - if true, this will convert records in our import file from
#   MARC8 encoding into UTF-8 encoding on output to index
marc.to_utf_8 = true

# - marc.unicode_normalize
#   Unicode characters found in the record can normalized as:
#    C (Canonical decomposition followed by canonical composition)
#    D (Canonical decomposition)
#    KC (Compatibility decomposition followed by canonical composition)
#    KD (Compatibility decomposition).
marc.unicode_normalize = C

# - marc.include_errors - when error in marc record, dump description of error
#   to field in solr index an alternative way to trap the indexing error
#   messages that are logged during index time.  Nice for staff b/c they can
#   search for errors and see ckey and record fields in discovery portal.  This
#   field is NOT used for other queries.  Solr schema.xml must have field
#   marc_error.
marc.include_errors = false

# - marc.ids_to_delete - name of file containing ids of SOLR index documents to
#   be deleted
marc.ids_to_delete =

# - marc.delete_record_id_mapper - if you have ids you'd like to alter on their
#   way into Solr, use this regular expression.
#marc.delete_record_id_mapper = u?([0-9]*).*->u$1

# - marc.delete_subfields - subfields NOT to be included in full Marc data
#   field in Solr index.
#marc.delete_subfields = 999o
